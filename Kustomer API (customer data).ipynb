{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8f7efc",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading conversations metadata for the range June 16, 2025 - June 30, 2025\n",
      "Downloaded conversations page 1\n",
      "Downloaded conversations page 2\n",
      "Downloaded conversations page 3\n",
      "Downloaded conversations page 4\n",
      "Downloaded conversations page 5\n",
      "Downloaded conversations page 6\n",
      "Downloaded conversations page 7\n",
      "Downloaded conversations page 8\n",
      "Downloaded conversations page 9\n",
      "Downloaded conversations page 10\n",
      "Downloaded conversations page 11\n",
      "Downloaded conversations page 12\n",
      "Downloaded conversations page 13\n",
      "Downloaded conversations page 14\n",
      "Downloaded conversations page 15\n",
      "Downloaded conversations page 16\n",
      "Downloaded conversations page 17\n",
      "Downloaded conversations page 18\n",
      "Downloaded conversations page 19\n",
      "Downloaded conversations page 20\n",
      "Downloaded conversations page 21\n",
      "Downloaded conversations page 22\n",
      "Downloaded conversations page 23\n",
      "Downloaded conversations page 24\n",
      "Downloaded conversations page 25\n",
      "Downloaded conversations page 26\n",
      "Downloaded conversations page 27\n",
      "Downloaded conversations page 28\n",
      "Downloaded conversations page 29\n",
      "Downloaded conversations page 30\n",
      "Downloaded conversations page 31\n",
      "Downloaded conversations page 32\n",
      "Downloaded conversations page 33\n",
      "Downloaded conversations page 34\n",
      "Downloaded conversations page 35\n",
      "Downloaded conversations page 36\n",
      "Downloaded conversations page 37\n",
      "Downloaded conversations page 38\n",
      "Downloaded conversations page 39\n",
      "Downloaded conversations page 40\n",
      "Downloaded conversations page 41\n",
      "Downloaded conversations page 42\n",
      "Downloaded conversations page 43\n",
      "Downloaded conversations page 44\n",
      "Downloaded conversations page 45\n",
      "Downloaded conversations page 46\n",
      "Downloaded conversations page 47\n",
      "Downloaded conversations page 48\n",
      "Downloaded conversations page 49\n",
      "Downloaded conversations page 50\n",
      "Downloaded conversations page 51\n",
      "Downloaded conversations page 52\n",
      "Downloaded conversations page 53\n",
      "Downloaded conversations page 54\n",
      "Downloaded conversations page 55\n",
      "Downloaded conversations page 56\n",
      "Downloaded conversations page 57\n",
      "Downloaded conversations page 58\n",
      "Downloaded conversations page 59\n",
      "Downloaded conversations page 60\n",
      "Downloaded conversations page 61\n",
      "Downloaded conversations page 62\n",
      "Downloaded conversations page 63\n",
      "Downloaded conversations page 64\n",
      "Downloaded conversations page 65\n",
      "Downloaded conversations page 66\n",
      "Downloaded conversations page 67\n",
      "Downloaded conversations page 68\n",
      "Downloaded conversations page 69\n",
      "Downloaded conversations page 70\n",
      "Downloaded conversations page 71\n",
      "Downloaded conversations page 72\n",
      "Downloaded conversations page 73\n",
      "Downloaded conversations page 74\n",
      "Downloaded conversations page 75\n",
      "Downloaded conversations page 76\n",
      "Downloaded conversations page 77\n",
      "Downloaded conversations page 78\n",
      "Downloaded conversations page 79\n",
      "Downloaded conversations page 80\n",
      "Downloaded conversations page 81\n",
      "Downloaded conversations page 82\n",
      "Downloaded conversations page 83\n",
      "Downloaded conversations page 84\n",
      "Downloaded conversations page 85\n",
      "Downloaded conversations page 86\n",
      "Downloaded conversations page 87\n",
      "Downloaded conversations page 88\n",
      "Downloaded conversations page 89\n",
      "Downloaded conversations page 90\n",
      "Downloaded conversations page 91\n",
      "Downloaded conversations page 92\n",
      "Downloaded conversations page 93\n",
      "Downloaded conversations page 94\n",
      "Downloaded conversations page 95\n",
      "Downloaded conversations page 96\n",
      "Downloaded conversations page 97\n",
      "Downloaded conversations page 98\n",
      "Downloaded conversations page 99\n",
      "Downloaded conversations page 100\n",
      "Finished fetching conversations metadata\n",
      "Finished saving conversations metadata\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import sys\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "# set date range\n",
    "start_date = \"2025-06-16\" # Start date in YYYY-MM-DD format \n",
    "end_date = \"2025-06-30\"\n",
    "# datetime.now().strftime('%Y-%m-%d') # Current date in YYYY-MM-DD format \n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Parse date string in YYYY-MM-DD format to datetime object\"\"\"\n",
    "    try:\n",
    "        return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        raise argparse.ArgumentTypeError(f\"Invalid date format: {date_str}. Please use YYYY-MM-DD\")\n",
    "\t\t\n",
    "def is_in_date_range(created_at, start_date, end_date):\n",
    "    \"\"\"Check if a timestamp is within the specified date range\"\"\"\n",
    "    # Convert ISO string to datetime object\n",
    "    created_date = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    \n",
    "    # Compare with start and end dates\n",
    "    return start_date <= created_date <= end_date\n",
    "\n",
    "# Load env variables\n",
    "environment_variables = {}\n",
    "with open(\"env\") as f:\n",
    "    for line in f:\n",
    "        key, value = line.strip().split(\"=\")\n",
    "        environment_variables[key] = value\n",
    "\t\t\n",
    "BASE_URL = environment_variables[\"BASE_URL\"]\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {environment_variables['API_KEY']}\"\n",
    "}\n",
    "\n",
    "def fetch_page(url, params):\n",
    "    resp = requests.get(url, params=params, headers=HEADERS)\n",
    "    if resp.status_code == 200:\n",
    "        data = resp.json().get(\"data\", None)\n",
    "        if(len(data)==0):\n",
    "            return None\n",
    "        return data\n",
    "    elif resp.status_code == 400 :\n",
    "        # no more pages\n",
    "        return None\n",
    "    else:\n",
    "        # unexpected error: let it propagate\n",
    "        resp.raise_for_status()\n",
    "\t\t\n",
    "def fetch_conversations():\n",
    "    # Start at page 1 and keep incrementing until empty\n",
    "    page = 1\n",
    "    all_convos = []\n",
    "    while True:\n",
    "        data = fetch_page(f\"{BASE_URL}/v1/conversations\", {\"page\": page, \"pageSize\": 1000})\n",
    "        if not data:\n",
    "            break\n",
    "        all_convos.extend(data)\n",
    "        print(f\"Downloaded conversations page {page}\")\n",
    "        page += 1\n",
    "    return all_convos\t\n",
    "\n",
    "def fetch_all_messages(convo):\n",
    "    convo_id = convo[\"id\"]\n",
    "    page = 1\n",
    "    messages = []\n",
    "    while True:\n",
    "        data = fetch_page(f\"{BASE_URL}/v1/conversations/{convo_id}/messages\", \n",
    "                          {\"page\": page, \"pageSize\": 1000})\n",
    "        if data is None:\n",
    "            break\n",
    "        messages.extend(data)\n",
    "        page += 1\n",
    "    return {\"conversationMeta\": convo, \"allMessages\": messages}\n",
    "\n",
    " # Only set end_date if we're using date filtering\n",
    "if start_date != None:\n",
    "    start_date = parse_date(start_date).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\t\n",
    "if end_date != None:\n",
    "    end_date = parse_date(end_date).replace(hour=23, minute=59, second=59, microsecond=999999)\n",
    "\t\n",
    "date_range_string = \"all\" if start_date is None and end_date is None else f\"{start_date.strftime('%B %d, %Y')} - {end_date.strftime('%B %d, %Y')}\"\n",
    "print(f\"Downloading conversations metadata for the range {date_range_string}\")\n",
    "\n",
    "# 1. Fetch all conversation metadata synchronously\n",
    "conversations = fetch_conversations()\n",
    "\n",
    "print(\"Finished fetching conversations metadata\")\n",
    "conversations = [c for c in conversations if (end_date == None and start_date == None) or is_in_date_range(c[\"attributes\"][\"createdAt\"], start_date, end_date)]\n",
    "with open(f\"conversations-condensed-2024.json\", \"w\") as f:\n",
    "    json.dump(conversations, f, indent=4)\n",
    "print(\"Finished saving conversations metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1af71354-8956-44e2-9564-6bc36b2fec23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # normalizing data\n",
    "# import pandas as pd\n",
    "\n",
    "# with open(\"conversations-condensed-2024.json\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# kustomer = pd.json_normalize(data)\n",
    "# kustomer.columns = [col.replace('.','_') for col in kustomer.columns]\n",
    "# kustomer.drop(columns = ['attributes_firstMessageIn_meta_Wait time',\n",
    "# \t\t\t\t\t\t 'attributes_firstMessageIn_meta_Wait time Last Queue',\n",
    "# \t\t\t\t\t\t 'attributes_lastMessageIn_meta_Wait time',\n",
    "# \t\t\t\t\t\t 'attributes_lastMessageIn_meta_Wait time Last Queue'],\n",
    "# \t\t\t  inplace=True)\n",
    "\n",
    "# # preview data\n",
    "# kustomer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4083703f-fcee-43e2-a630-376946f4a876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save to csv for uploading to Domo via CSV workbench\n",
    "# kustomer.to_csv(f\"Kustomer {date_range_string}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a1184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 2. Fetch messages in parallel threads\n",
    "# results = []\n",
    "# percentDone = 0\n",
    "# max_workers = 10  # tune based on your API rate limits & CPU\n",
    "# with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "#     future_to_convo = {executor.submit(fetch_all_messages, c): c for c in conversations}\n",
    "#     for future in as_completed(future_to_convo):\n",
    "#         convo = future_to_convo[future]\n",
    "#         try:\n",
    "#             full = future.result()\n",
    "#             results.append(full)\n",
    "#             percentDone += 1\n",
    "#             # print(f\"{convo['id']} % done: {((percentDone/len(conversations))*100):.2f}%\")\n",
    "#         except Exception as exc:\n",
    "#             print(f\"Error fetching {convo['id']}: {exc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d555ae2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(f\"conversations-with-messages-{date_range_string}.json\", \"w\") as f:\n",
    "#     json.dump(results, f, indent=4)\n",
    "# print(\"All done!\")\n",
    "\n",
    "# # normalizing data\n",
    "# import pandas as pd\n",
    "\n",
    "# with open(f\"conversations-with-messages-{date_range_string}.json\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# kustomer = pd.json_normalize(data)\n",
    "# kustomer.columns = [col.replace('.','_') for col in kustomer.columns]\n",
    "# kustomer.drop(columns = ['conversationMeta_attributes_firstMessageIn_meta_Wait time', \n",
    "# \t\t\t\t\t\t 'conversationMeta_attributes_lastMessageIn_meta_Wait time', \n",
    "# \t\t\t\t\t\t 'conversationMeta_attributes_firstMessageIn_meta_Wait time Last Queue', \n",
    "# \t\t\t\t\t\t 'conversationMeta_attributes_lastMessageIn_meta_Wait time Last Queue'],\n",
    "# \t\t\t  inplace=True)\n",
    "\n",
    "# # preview data\n",
    "# print(kustomer.head())\n",
    "# print(kustomer.info())\n",
    "\n",
    "# # save to csv for uploading to Domo via CSV Workbench\n",
    "# kustomer.to_csv(f\"conversations-with-messages-{date_range_string}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aac485f7-3cf8-4c1a-b4e3-6b18eaa41a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished retrieving customers for: 2025-06-16T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-17T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-18T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-19T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-20T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-21T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-22T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-23T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-24T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-25T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-26T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-27T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-28T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-29T00:00:00Z\n",
      "finished retrieving customers for: 2025-06-30T00:00:00Z\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def stay_in_while_loop(current_date):\n",
    "    if end_date is not None:\n",
    "        return current_date < end_date\n",
    "    else:\n",
    "        return current_date < datetime.now()\n",
    "\n",
    "def fetch_customers():\n",
    "    all_customers = []\n",
    "    current_date = start_date\n",
    "    params = {\n",
    "    'filter[createdAt][gte]': start_date.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "    'filter[createdAt][lt]': (start_date + timedelta(days=2)).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "        'page': 1,\n",
    "        'pageSize': 1000\n",
    "    }\n",
    "\n",
    "    while stay_in_while_loop(current_date):\n",
    "        customers_resp = requests.get(f\"{BASE_URL}/v1/customers\", params, headers=HEADERS)\n",
    "        if customers_resp.status_code == 200:\n",
    "            test = customers_resp.json().get(\"meta\",None).get(\"page\",None)\n",
    "\n",
    "            try:\n",
    "                while  customers_resp.status_code == 200 and customers_resp.json()[\"meta\"][\"page\"] <= customers_resp.json()[\"meta\"][\"totalPages\"] and customers_resp.json()[\"meta\"][\"page\"] <= 10:\n",
    "                    customers_resp_data = customers_resp.json().get(\"data\", None)\n",
    "                    params[\"page\"] += 1\n",
    "                    all_customers.extend(customers_resp_data)\n",
    "                    customers_resp = requests.get(f\"{BASE_URL}/v1/customers\", params, headers=HEADERS)\n",
    "            except Exception as e:\n",
    "                print(f\"Debug 0 {customers_resp.json()}\")\n",
    "                break\n",
    "        print(f\"finished retrieving customers for: {current_date.strftime('%Y-%m-%dT%H:%M:%SZ')}\")\n",
    "        current_date = current_date + timedelta(days=1)\n",
    "        params[\"filter[createdAt][gte]\"] = current_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        params[\"filter[createdAt][lt]\"] = (current_date + timedelta(days=2)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        params[\"page\"] = 1\n",
    "\n",
    "    \n",
    "    return all_customers\n",
    "\n",
    "customers = fetch_customers()\n",
    "with open(f\"customers-{date_range_string}.json\", \"w\") as f:\n",
    "    json.dump(customers, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b4b1c-408b-45ca-a37b-9419ee693c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
